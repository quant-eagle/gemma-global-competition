{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install polars datasets sentencepiece transformers sentence_transformers unbabel-comet keras keras-nlp scikit-learn jax tensorflow tensorflow-text tf-keras matplotlib fasttext wget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set the backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import keras\n",
    "\n",
    "# Disable HF Tokenizer parallelism\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# Set the backend\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
    "\n",
    "# Avoid memory fragmentation on JAX backend.\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"1.00\"\n",
    "\n",
    "# Enable mixed precision training\n",
    "keras.mixed_precision.set_global_policy(\"mixed_float16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup training config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class TrainingConfig:\n",
    "    token_limit: int = 128\n",
    "    dataset_limit: int = 10000\n",
    "    batch_size: int = 16\n",
    "    lora_rank: int = 4\n",
    "    epochs: int = 10\n",
    "    learning_rate: float = 2e-4\n",
    "    model_id = \"gemma2_instruct_2b_en\"\n",
    "\n",
    "training_config = TrainingConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import polars as pl\n",
    "\n",
    "ds = load_dataset(\"Helsinki-NLP/europarl\", \"cs-en\")\n",
    "df = ds[\"train\"].to_polars()\n",
    "\n",
    "# Reduce the dataset to our training limit\n",
    "df = df.head(training_config.dataset_limit)\n",
    "\n",
    "# Let's check the structure\n",
    "print(df.schema)\n",
    "print(\"\\nFirst row:\")\n",
    "print(df.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's normalize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the translation column\n",
    "df_norm = df.select(\n",
    "    [\n",
    "        pl.col(\"translation\").struct.field(\"en\").alias(\"en\"),\n",
    "        pl.col(\"translation\").struct.field(\"cs\").alias(\"cs\"),\n",
    "        pl.col(\"translation\").struct.field(\"cs\").str.len_chars().alias(\"cs_len\"),\n",
    "        pl.col(\"translation\").struct.field(\"en\").str.len_chars().alias(\"en_len\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Let's check the normalized structure\n",
    "print(df_norm.schema)\n",
    "print(\"\\nFirst row:\")\n",
    "print(df_norm.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to preprocess the data to get achieve high quality results.\n",
    "\n",
    "First, let's clean the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_texts(df):\n",
    "    \"\"\"\n",
    "    Clean the texts by replacing multiple spaces with a single space and stripping leading and trailing spaces.\n",
    "    We also filter out very short texts (less than 3 characters) and texts where one language is more than 2.5x longer than the other.\n",
    "    \"\"\"\n",
    "    return df.with_columns(\n",
    "        [\n",
    "            # Clean the English text\n",
    "            pl.col(\"en\")\n",
    "            .str.replace_all(r\"\\s+\", \" \")\n",
    "            .str.strip_chars()\n",
    "            .alias(\"en_clean\"),\n",
    "            # Clean the Czech text\n",
    "            pl.col(\"cs\")\n",
    "            .str.replace_all(r\"\\s+\", \" \")\n",
    "            .str.strip_chars()\n",
    "            .alias(\"cs_clean\"),\n",
    "        ]\n",
    "    ).filter(\n",
    "        # Filter out rows with non a-Z characters\n",
    "        ~pl.col(\"cs_clean\").str.contains(r\"^[a-zA-Z]+$\")\n",
    "        & ~pl.col(\"en_clean\").str.contains(r\"^[a-zA-Z]+$\")\n",
    "        # Filter out very short texts (less than 3 characters)\n",
    "        & (pl.col(\"cs_len\") >= 3)\n",
    "        & (pl.col(\"en_len\") >= 3)\n",
    "        # This helps remove poor quality or misaligned translations\n",
    "        & (pl.col(\"cs_len\") / pl.col(\"en_len\") <= 2.5)  # Czech text not too long compared to English\n",
    "        & (pl.col(\"en_len\") / pl.col(\"cs_len\") <= 2.5)  # English text not too long compared to Czech\n",
    "    )\n",
    "\n",
    "print(f\"Dataset shape: {df_norm.shape}\")\n",
    "df_norm = clean_texts(df_norm)\n",
    "print(f\"Dataset shape after cleaning: {df_norm.shape}\")\n",
    "print(df_norm.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run a language detection check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import os\n",
    "import wget\n",
    "from tqdm import tqdm\n",
    "\n",
    "def detect_language(df, threshold=0.8, batch_size=100):\n",
    "    \"\"\"\n",
    "    Detect the language of the text.\n",
    "    \"\"\"\n",
    "    print(f\"Detecting language of the text with threshold {threshold} and batch size {batch_size}\")\n",
    "\n",
    "    # Load the fasttext model\n",
    "    model_path = \"models/fasttext/lid.176.bin\"\n",
    "    if not os.path.exists(model_path):\n",
    "        os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "        wget.download(\"https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin\", out=model_path)\n",
    "\n",
    "    model = fasttext.load_model(model_path)\n",
    "\n",
    "    def predict_language(text):\n",
    "        \"\"\"\n",
    "        Check if the text is in the expected language.\n",
    "        \"\"\"\n",
    "        prediction = model.predict(text, k=1)\n",
    "        return prediction\n",
    "\n",
    "    # Process in batches\n",
    "    cs_clean = df['cs_clean'].to_list()\n",
    "    en_clean = df['en_clean'].to_list()\n",
    "\n",
    "    cs_results = []\n",
    "    en_results = []\n",
    "    bad_languages = []\n",
    "\n",
    "    for i in range(0, len(cs_clean), batch_size):\n",
    "        batch_cs = cs_clean[i:i+batch_size]\n",
    "        batch_en = en_clean[i:i+batch_size]\n",
    "\n",
    "        # Check if the text is in the expected language\n",
    "        for text in tqdm(batch_cs, desc=\"Checking Czech language\"):\n",
    "            result = predict_language(text)\n",
    "            if result[0][0] == \"__label__cs\":\n",
    "                cs_results.append(True)\n",
    "            else:\n",
    "                cs_results.append(False)\n",
    "                bad_languages.append(result[0][0])\n",
    "\n",
    "        for text in tqdm(batch_en, desc=\"Checking English language\"):\n",
    "            result = predict_language(text)\n",
    "            if result[0][0] == \"__label__en\":\n",
    "                en_results.append(True)\n",
    "            else:\n",
    "                en_results.append(False)\n",
    "                bad_languages.append(result[0][0])\n",
    "\n",
    "    print(f\"Detected bad languages: {bad_languages}\")\n",
    "\n",
    "    return df.with_columns(\n",
    "        [\n",
    "            pl.Series(\"is_valid_cs\", cs_results),\n",
    "            pl.Series(\"is_valid_en\", en_results)\n",
    "        ]\n",
    "    ).filter(pl.col(\"is_valid_cs\") & pl.col(\"is_valid_en\"))\n",
    "\n",
    "print(f\"Dataset shape: {df_norm.shape}\")\n",
    "df_norm = detect_language(df_norm)\n",
    "print(f\"Dataset shape after language detection: {df_norm.shape}\")\n",
    "print(df_norm.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's filter out the rows based on similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/LaBSE')\n",
    "\n",
    "def filter_similar_texts(df, threshold=0.8, batch_size=100):\n",
    "    \"\"\"\n",
    "    Filter out the rows based on similarity.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Filtering out rows with similarity less than {threshold}\")\n",
    "    print(f\"Processing in batches of {batch_size} rows\")\n",
    "    \n",
    "    # Process in batches\n",
    "    cs_clean = df['cs_clean'].to_list()\n",
    "    en_clean = df['en_clean'].to_list()\n",
    "    \n",
    "    similarities = []\n",
    "\n",
    "    # Use GPU if available\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    for i in range(0, len(cs_clean), batch_size):\n",
    "        batch_cs = cs_clean[i:i+batch_size]\n",
    "        batch_en = en_clean[i:i+batch_size]\n",
    "        \n",
    "        # Compute the embeddings\n",
    "        with torch.no_grad():\n",
    "            embeddings_cs = model.encode(batch_cs, convert_to_tensor=True)\n",
    "            embeddings_en = model.encode(batch_en, convert_to_tensor=True)\n",
    "        \n",
    "        # Compute the similarity\n",
    "        batch_similarities = torch.nn.functional.cosine_similarity(embeddings_cs, embeddings_en, dim=1)\n",
    "        similarities.extend(batch_similarities.cpu().numpy())\n",
    "        \n",
    "    return df.with_columns(pl.Series(\"similarity\", similarities)).filter(pl.col(\"similarity\") > threshold)\n",
    "\n",
    "print(f\"Dataset shape: {df_norm.shape}\")\n",
    "df_norm = filter_similar_texts(df_norm)\n",
    "print(f\"Filtered dataset shape: {df_norm.shape}\")\n",
    "print(df_norm.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's perform an alignment check. We will use COMET to check the quality of the alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "from comet import load_from_checkpoint\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the COMET model\n",
    "model_path = snapshot_download(\"Unbabel/wmt22-comet-da\")\n",
    "model_checkpoint_path = f\"{model_path}/checkpoints/model.ckpt\"\n",
    "model = load_from_checkpoint(model_checkpoint_path)\n",
    "\n",
    "def filter_by_quality(df, treshold = 0.4, batch_size = 100):\n",
    "    \"\"\"\n",
    "    Filter out the rows based on the quality of the alignment.\n",
    "    \"\"\"\n",
    "    # Use GPU if available\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    # Get texts\n",
    "    cs_clean = df[\"cs_clean\"].to_list()\n",
    "    en_clean = df[\"en_clean\"].to_list()\n",
    "\n",
    "    # Prepare data for COMET\n",
    "    data = [\n",
    "        {\"src\": cs, \"mt\": en, \"ref\": None}\n",
    "        for cs, en in zip(cs_clean, en_clean)\n",
    "    ]\n",
    "    \n",
    "    # Get scores from COMET\n",
    "    predictions = model.predict(data, batch_size=batch_size)\n",
    "    scores = predictions.scores\n",
    "\n",
    "    return df.with_columns(\n",
    "        [pl.Series(\"quality_score\", scores)]\n",
    "    ).filter(pl.col(\"quality_score\") > treshold)\n",
    "\n",
    "\n",
    "print(f\"Dataset shape: {df_norm.shape}\")\n",
    "df_norm = filter_by_quality(df_norm)\n",
    "print(f\"Filtered dataset shape: {df_norm.shape}\")\n",
    "print(df_norm.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the distribution of the quality scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at distribution\n",
    "print(\n",
    "    df_norm.select(\n",
    "        [\n",
    "            pl.col(\"quality_score\").quantile(0.25).alias(\"25th_percentile\"),\n",
    "            pl.col(\"quality_score\").quantile(0.5).alias(\"median\"),\n",
    "            pl.col(\"quality_score\").quantile(0.75).alias(\"75th_percentile\"),\n",
    "            pl.col(\"quality_score\").mean().alias(\"mean\"),\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that the quality of the alignment is pretty good for most of the rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's normalize the dataset to the instruction format and save the dataset to a parquet file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def instruction_format(x):\n",
    "    \"\"\"Format input text into an instruction format for translation.\n",
    "\n",
    "    Args:\n",
    "        x: Dictionary containing 'en_clean' (English text) and 'cs_clean' (Czech translation)\n",
    "\n",
    "    Returns:\n",
    "        str: Formatted instruction string with the following structure:\n",
    "            <start_of_turn>user\n",
    "            Přelož tento text z angličtiny do češtiny.\n",
    "            \"{English text}\"\n",
    "            <end_of_turn>\n",
    "            <start_of_turn>model\n",
    "            {Czech translation}<end_of_turn>\n",
    "    \"\"\"\n",
    "    return f\"<start_of_turn>user\\nPřelož tento text z angličtiny do češtiny.\\n\\\"{x['en_clean']}\\\"<end_of_turn>\\n<start_of_turn>model\\n{x['cs_clean']}<end_of_turn>\"\n",
    "\n",
    "finetune_df = df_norm.with_columns(\n",
    "    [\n",
    "        pl.struct([\"en_clean\", \"cs_clean\"])\n",
    "        .map_elements(instruction_format, return_dtype=pl.Utf8)\n",
    "        .alias(\"instruction\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(finetune_df.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No we need to tokenize the dataset. First we will load the tokenizer and test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_nlp\n",
    "\n",
    "# Load the Gemma2 tokenizer\n",
    "tokenizer = keras_nlp.models.GemmaTokenizer.from_preset(\n",
    "    training_config.model_id\n",
    ")\n",
    "\n",
    "# Test the tokenizer\n",
    "print(tokenizer(\"Hello, world!\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's tokenize the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Dataset shape: {finetune_df.shape}\")\n",
    "print(f\"Token limit: {training_config.token_limit}\")\n",
    "\n",
    "finetune_df = finetune_df.with_columns(\n",
    "    [\n",
    "        pl.col(\"instruction\")\n",
    "        .map_elements(lambda x: tokenizer(x).tolist(), return_dtype=pl.List(pl.Int32))\n",
    "        .alias(\"tokens\")\n",
    "    ]\n",
    ").filter(\n",
    "    pl.col(\"tokens\").list.len() <= training_config.token_limit\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check the token distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "token_lengths = finetune_df[\"tokens\"].map_elements(len, return_dtype=pl.Int32)\n",
    "print(\"Token length statistics:\")\n",
    "print(f\"Mean: {token_lengths.mean()}\")\n",
    "print(f\"Median: {token_lengths.median()}\")\n",
    "print(f\"95th percentile: {token_lengths.quantile(0.95)}\")\n",
    "print(f\"Max: {token_lengths.max()}\")\n",
    "\n",
    "# Plot the token length distribution\n",
    "plt.hist(token_lengths, bins=50)\n",
    "plt.title(\"Token Length Distribution\")\n",
    "plt.xlabel(\"Token Length\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, filter to the token limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_df = finetune_df.select(\n",
    "    [\n",
    "        pl.col(\"instruction\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"Dataset shape post-tokenization: {finetune_df.shape}\")\n",
    "print(finetune_df.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now finally, let's calculate the dropout rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropout rate is the percentage of rows that are filtered out.\n",
    "dropout_rate = (len(df) - len(finetune_df)) / len(df)\n",
    "print(f\"Dropout rate: {dropout_rate:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dropout rate is pretty high, but it's a good thing that we have a lot of data to work with and we aim for high quality results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the dataset is ready for the next step. We will use it to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# First split into train and temp (80/20)\n",
    "train_df, temp_df = train_test_split(finetune_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Then split temp into validation and test (50/50, resulting in 10/10 of original)\n",
    "valid_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Save all splits to parquet files\n",
    "train_df.write_parquet(\n",
    "    file=\"data/processed/gemma_cs_train.parquet\", compression=\"zstd\"\n",
    ")\n",
    "valid_df.write_parquet(\n",
    "    file=\"data/processed/gemma_cs_valid.parquet\", compression=\"zstd\"\n",
    ")\n",
    "test_df.write_parquet(\n",
    "    file=\"data/processed/gemma_cs_test.parquet\", compression=\"zstd\"\n",
    ")\n",
    "\n",
    "print(f\"Train size: {len(train_df)}\")\n",
    "print(f\"Validation size: {len(valid_df)}\")\n",
    "print(f\"Test size: {len(test_df)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras_nlp\n",
    "\n",
    "gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(training_config.model_id)\n",
    "gemma_lm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the inference of our prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'Přelož tento text z angličtiny do češtiny:\\n\"Hello, world!\"'\n",
    "print(\n",
    "    gemma_lm.generate(\n",
    "        prompt,\n",
    "        max_length=training_config.token_limit,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LoRA Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable LoRA on the model\n",
    "gemma_lm.backbone.enable_lora(rank=training_config.lora_rank)\n",
    "gemma_lm.summary()\n",
    "\n",
    "# Control memory usage\n",
    "gemma_lm.preprocessor.sequence_length = training_config.token_limit\n",
    "\n",
    "# Setup optimizer\n",
    "optimizer = keras.optimizers.AdamW(\n",
    "    learning_rate=training_config.learning_rate,\n",
    "    weight_decay=0.01,\n",
    "    epsilon=1e-6, # Default is 1e-8, but we need to use mixed precision training\n",
    ")\n",
    "\n",
    "# Exclude layernorm and bias terms from decay.\n",
    "optimizer.exclude_from_weight_decay(var_names=[\"bias\", \"scale\"])\n",
    "\n",
    "# Setup loss\n",
    "loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# Setup metrics\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    "\n",
    "# Compile the model\n",
    "gemma_lm.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce the dataset to Keras expected format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_df[\"instruction\"].to_list()\n",
    "valid_dataset = valid_df[\"instruction\"].to_list()\n",
    "\n",
    "print(f\"Train dataset shape: {len(train_dataset)}\")\n",
    "print(train_dataset[0])\n",
    "print(\"\\n\")\n",
    "\n",
    "print(f\"Valid dataset shape: {len(valid_dataset)}\")\n",
    "print(valid_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is now ready for training. Let's train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from wandb.integration.keras import WandbMetricsLogger\n",
    "import wandb\n",
    "\n",
    "class CustomCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(f\"Epoch {epoch} finished\")\n",
    "        model_name = f\"gemma_cs_{training_config.lora_rank}_epoch{epoch+1}.lora.h5\"\n",
    "        gemma_lm.backbone.save_lora_weights(model_name)\n",
    "        print(f\"Model {model_name} saved\")\n",
    "\n",
    "        # Eval on prompt\n",
    "        prompt = \"Přelož tento text z angličtiny do češtiny.\\n\\\"Hello, world!\\\"\"\n",
    "        print(f\"Prompt: {prompt}\")\n",
    "        print(\n",
    "            f\"Response: {gemma_lm.generate(prompt, max_length=training_config.token_limit)}\"\n",
    "        )\n",
    "\n",
    "# Initialize a new W&B run\n",
    "wandb.init(config={\n",
    "    \"learning_rate\": training_config.learning_rate,\n",
    "    \"epochs\": training_config.epochs,\n",
    "    \"batch_size\": training_config.batch_size,\n",
    "    \"lora_rank\": training_config.lora_rank,\n",
    "    \"token_limit\": training_config.token_limit,\n",
    "    \"model\": \"gemma2_instruct_2b_en\",\n",
    "    \"task\": \"czech-context\"\n",
    "})\n",
    "\n",
    "# Convert lists to TensorFlow datasets\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(train_dataset)\n",
    "valid_ds = tf.data.Dataset.from_tensor_slices(valid_dataset)\n",
    "\n",
    "# Configure datasets for performance\n",
    "train_ds = train_ds.batch(training_config.batch_size)\n",
    "valid_ds = valid_ds.batch(training_config.batch_size)\n",
    "\n",
    "# Enable prefetching to improve performance\n",
    "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "valid_ds = valid_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Train the model\n",
    "history = gemma_lm.fit(\n",
    "    train_ds,\n",
    "    validation_data=valid_ds,\n",
    "    epochs=training_config.epochs,\n",
    "    callbacks=[CustomCallback(), WandbMetricsLogger()],\n",
    ")\n",
    "\n",
    "# Plot the training loss\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.show()\n",
    "\n",
    "# Plot the accuracy\n",
    "plt.plot(history.history[\"sparse_categorical_accuracy\"])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gemma-czech-adaptation-iLYBdvQN-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
